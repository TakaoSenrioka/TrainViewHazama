import os
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import subprocess

PUBLIC_DIR = "public"
os.makedirs(PUBLIC_DIR, exist_ok=True)

CUSTOM_FILE = os.path.join(PUBLIC_DIR, "custom.csv")

def scrape_and_save():
    df = pd.read_csv("routes.csv")
    results = []

    for index, row in df.iterrows():
        line_name = row["è·¯ç·šå"]
        url = row["URL"]
        print(f"ğŸšƒ {line_name} ã‚’å–å¾—ä¸­...")

        try:
            response = requests.get(url, timeout=10)
            response.encoding = response.apparent_encoding
            soup = BeautifulSoup(response.text, "html.parser")

            suspend = soup.find("dd", class_="trouble suspend")
            trouble = None if suspend else soup.find("dd", class_="trouble")

            if suspend:
                info_text = suspend.get_text(strip=True)
            elif trouble:
                info_text = trouble.get_text(strip=True)
            else:
                info_text = "å¹³å¸¸é‹è»¢"

            if "è¦‹åˆã‚ã›" in info_text:
                status = "é‹è»¢è¦‹åˆã‚ã›"
            elif "é…ã‚Œ" in info_text:
                status = "é…å»¶"
            elif info_text == "å¹³å¸¸é‹è»¢":
                status = "å¹³å¸¸é‹è»¢"
            else:
                status = "ãã®ä»–"

            results.append({
                "è·¯ç·šå": line_name,
                "é‹è¡Œæƒ…å ±": info_text,
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status,
            })

        except Exception as e:
            print(f"âŒ {line_name} ã‚¨ãƒ©ãƒ¼: {e}")
            results.append({
                "è·¯ç·šå": line_name,
                "é‹è¡Œæƒ…å ±": "å–å¾—ã‚¨ãƒ©ãƒ¼",
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "å–å¾—å¤±æ•—",
            })

    output_path = os.path.join(PUBLIC_DIR, "result.csv")
    pd.DataFrame(results).to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"âœ… {output_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")

def wait_and_accept_input():
    print("5åˆ†å¾…æ©Ÿä¸­ã§ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Œã°å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆEnterã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰ï¼š")
    user_input = input().strip()
    if user_input:
        with open(CUSTOM_FILE, "a", encoding="utf-8") as f:
            f.write(user_input + "\n")
        print(f"ğŸ“¥ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ {CUSTOM_FILE} ã«è¿½è¨˜ã—ã¾ã—ãŸã€‚")
    else:
        print("ğŸ“¤ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã—ã€‚ä½•ã‚‚å¤‰æ›´ã—ã¾ã›ã‚“ã€‚")

def git_push_if_needed():
    # å·®åˆ†ãŒã‚ã‚‹ã‹ç¢ºèª
    status = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True)
    if status.stdout.strip():  # å¤‰æ›´ãŒã‚ã‚‹å ´åˆã®ã¿ push
        try:
            subprocess.run(["git", "add", "."], check=True)
            subprocess.run(["git", "commit", "-m", "Auto update CSV files"], check=True)
            subprocess.run(["git", "push"], check=True)
            print("ğŸš€ GitHub ã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸã€‚")
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸ Gitæ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("ğŸŸ¢ å¤‰æ›´ãªã—ã€‚GitHubã¸ã®ãƒ—ãƒƒã‚·ãƒ¥ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    while True:
        scrape_and_save()
        wait_and_accept_input()
        git_push_if_needed()
        time.sleep(5 * 60)
